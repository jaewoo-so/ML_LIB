{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 데이터 만들기\\n2. 모델 제너레이터 만들기 \\n3. 모델 생성 파라미터, 피팅 파라미터 만들기 \\n4. 성능평가 메트릭 정의하기 :  f : y , pred -> value\\n5. training_fixedTest 실행하기 \\n6. 유틸에 테스트 데이터에 대한 성능평가, 또는 저장 등을 하기 \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'E:\\01_PProj\\ML_LIB')\n",
    "\n",
    "\n",
    "import Lib_sjw.training_blending as tr\n",
    "import Lib_sjw.model_interface as mi\n",
    "import Lib_sjw.model_parmas as mp\n",
    "import Lib_sjw.evaluator as ev\n",
    "import Lib_sjw.classification_util as cu\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing , load_iris , load_breast_cancer\n",
    "from sklearn.metrics import mean_squared_error , roc_auc_score , precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "1. 데이터 만들기\n",
    "2. 모델 제너레이터 만들기 \n",
    "3. 모델 생성 파라미터, 피팅 파라미터 만들기 \n",
    "4. 성능평가 메트릭 정의하기 :  f : y , pred -> value\n",
    "5. training_fixedTest 실행하기 \n",
    "6. 유틸에 테스트 데이터에 대한 성능평가, 또는 저장 등을 하기 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Test_blending_Binary(xtrain , ytrain , xtest  , blending_fold = 5 , verbose = False):\n",
    "    # name list \n",
    "    name_list = ['xgb',\n",
    "                 'lgb',\n",
    "                 #'cat',\n",
    "                 'rfc',\n",
    "                 'svm',\n",
    "                 'gpc',\n",
    "                 'lda',\n",
    "                 'qda']\n",
    "    # model_list , param_list , \n",
    "    model_list = OrderedDict()    \n",
    "    model_list = OrderedDict()    \n",
    "    model_list['xgb']  = mi.myXGBBinary()\n",
    "    model_list['lgb']  = mi.myLGBMBinary()\n",
    "    model_list['cat']  = mi.myCatBoostBinary()\n",
    "    model_list['rfc']  = mi.myRandomForestBinary()\n",
    "    model_list['svm']  = mi.mySVMBinary()\n",
    "    model_list['gpc']  = mi.myGPBinary()\n",
    "    model_list['lda']  = mi.myLDABinary()\n",
    "    model_list['qda']  = mi.myQDABinary()\n",
    "    \n",
    "    param_list = OrderedDict ( )\n",
    "    param_list['xgb'] = mp .param_xgb ('binary' , len(np.unique(ytrain)) , use_gpu= False )\n",
    "    param_list['lgb'] = mp .param_lgbm('binary' , len(np.unique(ytrain)) , use_gpu= False )\n",
    "    param_list['cat'] = mp .param_cat ('binary' , use_gpu= True , is_unbalance= False )\n",
    "    param_list['rfc'] = mp .param_rf ('binary' )\n",
    "    param_list['svm'] = mp .param_svm ('binary' )\n",
    "    param_list['gpc'] = mp .param_gpc ('binary' )\n",
    "    param_list['lda'] = mp .param_lda ( )\n",
    "    param_list['qda'] = mp .param_qda ( )\n",
    "    \n",
    "    #fitting parmas\n",
    "    fitpm_list = OrderedDict()\n",
    "\n",
    "    for name in name_list:\n",
    "            fitpm_list[name] = {}\n",
    "    fitpm_list['lgb'] = {'early_stopping_rounds' : 12 , 'verbose' : -1}\n",
    "    #fit_cat = {}\n",
    "    #fit_xgb = {}\n",
    "    \n",
    "    # metric func\n",
    "    metric_func = roc_auc_score\n",
    "    \n",
    "    # Result\n",
    "    result_list = OrderedDict()\n",
    "\n",
    "    # Training \n",
    "    for name in name_list:\n",
    "        print(name)\n",
    "        train_pred , test_pred , fold_metric = tr.training_blending_fixedTest('binary' , model_list[name] , param_list[name] , fitpm_list[name] ,  \n",
    "                                                                                    metric_func , xtrain , ytrain , xtest , blending_fold , verbose ) \n",
    "        result_list[name] = [train_pred , test_pred , fold_metric ]\n",
    "    return result_list\n",
    "\n",
    "def Test_blending_Binary_TestFold(X , y , nfold_test , blending_fold , verbose = True):\n",
    "    # name list \n",
    "    name_list = ['xgb',\n",
    "                 'lgb',\n",
    "                 #'cat',\n",
    "                 'rfc',\n",
    "                 'svm',\n",
    "                 'gpc',            \n",
    "                 'lda',\n",
    "                 'qda']\n",
    "    # model_list , param_list , \n",
    "    model_dict = OrderedDict()    \n",
    "    model_dict['xgb']  = mi.myXGBBinary()\n",
    "    model_dict['lgb']  = mi.myLGBMBinary()\n",
    "    model_dict['cat']  = mi.myCatBoostBinary()\n",
    "    model_dict['rfc']  = mi.myRandomForestBinary()\n",
    "    model_dict['svm']  = mi.mySVMBinary()\n",
    "    model_dict['gpc']  = mi.myGPBinary()\n",
    "    model_dict['lda']  = mi.myLDABinary()\n",
    "    model_dict['qda']  = mi.myQDABinary()\n",
    "    \n",
    "    param_list = OrderedDict ( )\n",
    "    param_list['xgb'] = mp .param_xgb ('binary' , len(np.unique(y)) , use_gpu= False )\n",
    "    param_list['lgb'] = mp .param_lgbm('binary' , len(np.unique(y)) , use_gpu= False )\n",
    "    param_list['cat'] = mp .param_cat ('binary' , use_gpu= True , is_unbalance= False )\n",
    "    param_list['rfc'] = mp .param_rf ('binary' )\n",
    "    param_list['svm'] = mp .param_svm ('binary' )\n",
    "    param_list['gpc'] = mp .param_gpc ('binary' )\n",
    "    param_list['lda'] = mp .param_lda ( )\n",
    "    param_list['qda'] = mp .param_qda ( )\n",
    "    \n",
    "    #fitting parmas\n",
    "    fitpm_list = OrderedDict()\n",
    "    for name in name_list:\n",
    "            fitpm_list[name] = {}\n",
    "    fitpm_list['lgb'] = {'early_stopping_rounds' : 12 , 'verbose' : -1}\n",
    "    #fit_cat = {}\n",
    "    #fit_xgb = {}\n",
    "    \n",
    "    # metric func\n",
    "    metric_func = roc_auc_score\n",
    "    \n",
    "    # Result\n",
    "    result_list = OrderedDict()\n",
    "    auc_score_list = OrderedDict()\n",
    "\n",
    "    for name in name_list:\n",
    "        print(name)\n",
    "        test_fold_index , fold_train_pred , fold_test_pred, mean_fold_score = tr.training_blending_Testfold_noVal('binary' , model_dict[name] , param_list[name] , fitpm_list[name] ,  metric_func , \n",
    "                                                                     X , y , nfold_test , blending_fold , verbose ) \n",
    "        result_list[name] = [test_fold_index , fold_train_pred , fold_test_pred, mean_fold_score]\n",
    "        print('done')\n",
    "    print('Test_Classification_TestFold Compelte')    \n",
    "    return result_list\n",
    "#endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_test(): # 인덱스로 나눌때 iloc를 써야한다. loc쓰면 경우에 따라서 nan이 리턴되는 경우도 있었다. \n",
    "    data = load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    df = pd.DataFrame(X, columns=data['feature_names'])\n",
    "    df['target'] = y\n",
    "    df = df.reset_index(drop=True)\n",
    "    X = df.iloc[:, :-1].astype('float16')\n",
    "    y = df.iloc[:, -1]\n",
    "    y=y.reset_index(drop=True)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)\n",
    "    '''\n",
    "    #확인 완료 \n",
    "    print(xtrain.isna().any())\n",
    "    print(xtest.isna().any())\n",
    "    print(ytrain.isna().any())\n",
    "    print(ytest.isna().any())\n",
    "    '''\n",
    "    Test_blending_Binary(xtrain , ytrain , xtest , 5,False)\n",
    "    Test_blending_Binary_TestFold(X,y,2,2)\n",
    "\n",
    "def np_test():\n",
    "    data = load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    df = pd.DataFrame()\n",
    "    xtrain , xtest , ytrain , ytest = train_test_split(X , y , test_size = 0.2 )\n",
    "    Test_blending_Binary(xtrain , ytrain , xtest , 5,False)\n",
    "    Test_blending_Binary_TestFold(X, y, 3, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb\n",
      "lgb\n",
      "rfc\n",
      "svm\n",
      "gpc\n",
      "lda\n",
      "qda\n",
      "xgb\n",
      "done\n",
      "lgb\n",
      "done\n",
      "rfc\n",
      "done\n",
      "svm\n",
      "done\n",
      "gpc\n",
      "done\n",
      "lda\n",
      "done\n",
      "qda\n",
      "done\n",
      "Test_Classification_TestFold Compelte\n"
     ]
    }
   ],
   "source": [
    "df_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:00) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5f39bb82ffeabb2834152b266f040325fd5c8b514dc714057e2f77d420cc596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
